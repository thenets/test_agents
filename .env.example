# ==============================================================================
# AI Agent Examples - Environment Configuration
# ==============================================================================
# Copy this file to .env and fill in your API keys
# This project supports multiple LLM providers

# ==============================================================================
# OpenRouter Configuration (Cloud LLM Provider)
# ==============================================================================
# Get your API key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# Default model for OpenRouter (can be overridden in specific examples)
# Popular options:
# - deepseek/deepseek-chat (good balance of cost/performance)
# - openai/gpt-4o-mini (OpenAI's efficient model)
# - anthropic/claude-3-haiku (Anthropic's fast model)
# - google/gemini-flash-1.5 (Google's model)
# - meta-llama/llama-3.1-8b-instruct:free (free option)
MODEL_NAME=openai/gpt-4o-mini

# ==============================================================================
# Local Ollama Configuration (Default for most examples)
# ==============================================================================
# Ollama runs locally and provides API-compatible interface
# Install from: https://ollama.ai
# Required models: ollama pull gpt-oss:20b && ollama pull mistral && ollama pull gemma3:1b
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_API_KEY=ollama

# Default models used in examples
OLLAMA_DEFAULT_MODEL=mistral
OLLAMA_LARGE_MODEL=gpt-oss:20b
OLLAMA_SMALL_MODEL=gemma3:1b

# ==============================================================================
# OpenAI Configuration (if using direct OpenAI API)
# ==============================================================================
# Get your API key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_MODEL=gpt-4o-mini

# ==============================================================================
# Anthropic Configuration (if using direct Anthropic API)
# ==============================================================================
# Get your API key from: https://console.anthropic.com/
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# ANTHROPIC_MODEL=claude-3-haiku-20240307

# ==============================================================================
# Search Configuration
# ==============================================================================
# DuckDuckGo search is used in search agent examples
# No API key required - uses ddg-search library

# ==============================================================================
# General Settings
# ==============================================================================
# Temperature for LLM responses (0.0 = deterministic, 1.0 = creative)
LLM_TEMPERATURE=0.1

# Maximum tokens for responses
MAX_TOKENS=2048

# Timeout for API requests (seconds)
API_TIMEOUT=30

# ==============================================================================
# Development Settings
# ==============================================================================
# Set to true to enable debug logging
DEBUG=false

# Set to true to enable verbose output in examples
VERBOSE=false

# ==============================================================================
# Example-specific Configuration
# ==============================================================================
# These can be used by specific examples that need additional configuration

# For MCP agent examples
MCP_SERVER_URL=localhost:3000

# For tool integration examples
CALCULATOR_PRECISION=2

# For multi-agent examples
AGENT_COLLABORATION_ENABLED=true
